{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96056bed-2c4f-4330-825d-844c0a0abf78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Trained and compared Linear and Ridge regression models, logging parameters, metrics, and signatures using MLflow with Unity Catalog governance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "c7f97870-7861-41e8-8b7e-8ffac2c6fd10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/Volumes/workspace/ecommerce/ecommerce_data/2019-Nov.csv</td><td>2019-Nov.csv</td><td>9006762395</td><td>1767962633000</td></tr><tr><td>dbfs:/Volumes/workspace/ecommerce/ecommerce_data/2019-Oct.csv</td><td>2019-Oct.csv</td><td>5668612855</td><td>1767962553000</td></tr><tr><td>dbfs:/Volumes/workspace/ecommerce/ecommerce_data/delta/</td><td>delta/</td><td>0</td><td>1768891934121</td></tr><tr><td>dbfs:/Volumes/workspace/ecommerce/ecommerce_data/incremental/</td><td>incremental/</td><td>0</td><td>1768891934121</td></tr><tr><td>dbfs:/Volumes/workspace/ecommerce/ecommerce_data/parquet/</td><td>parquet/</td><td>0</td><td>1768891934121</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/Volumes/workspace/ecommerce/ecommerce_data/2019-Nov.csv",
         "2019-Nov.csv",
         9006762395,
         1767962633000
        ],
        [
         "dbfs:/Volumes/workspace/ecommerce/ecommerce_data/2019-Oct.csv",
         "2019-Oct.csv",
         5668612855,
         1767962553000
        ],
        [
         "dbfs:/Volumes/workspace/ecommerce/ecommerce_data/delta/",
         "delta/",
         0,
         1768891934121
        ],
        [
         "dbfs:/Volumes/workspace/ecommerce/ecommerce_data/incremental/",
         "incremental/",
         0,
         1768891934121
        ],
        [
         "dbfs:/Volumes/workspace/ecommerce/ecommerce_data/parquet/",
         "parquet/",
         0,
         1768891934121
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs\n",
    "ls /Volumes/workspace/ecommerce/ecommerce_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "644976fc-833a-4568-b676-970327462ea5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e28c1c9-e9aa-4c9f-b04b-92ad2af5e4d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "features_df = spark.table(\"ecommerce.gold.user_features_ml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae69f26c-233d-4ac2-93d0-856af3dc807e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_df = features_df.select(\"views\",\"sessions\",\"purchases\",\"view_to_purchase_rate\",\"purchase_per_session\",\"total_spent\").fillna(0)\n",
    "pdf = model_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "137ee21b-e6d0-4ff1-b5f7-eeb9721a0c5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X = pdf.drop(columns=[\"total_spent\"])\n",
    "y = pdf[\"total_spent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34e33f09-1207-4993-936b-941de430c2d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58994718-d09c-4822-b106-e9f1c62aed46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "065a499f-1547-4fac-aa71-71595b40fdb7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 9"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/20 06:52:29 WARNING mlflow.models.signature: Failed to infer schema for inputs. Setting schema to `Schema([ColSpec(type=AnyType())]` as default. Note that MLflow doesn't validate data types during inference for AnyType. To see the full traceback, set logging level to DEBUG.\nRegistered model 'user_spend_regression' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 417.62571368386665\nR2: 0.5899802048424623\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '3' of model 'workspace.default.user_spend_regression'.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mlflow.models import infer_signature\n",
    "with mlflow.start_run(run_name=\"linear_regression_baseline\"):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Compute RMSE manually since 'squared' argument is not supported\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"model_type\", \"LinearRegression\")\n",
    "    mlflow.log_param(\"train_rows\", len(X_train))\n",
    "    mlflow.log_param(\"test_rows\", len(X_test))\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "\n",
    "    # Infer model signature\n",
    "    signature = infer_signature(X_train, model.predict(X_train))\n",
    "\n",
    "    # Log model with signature\n",
    "    mlflow.sklearn.log_model(\n",
    "        model,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=\"user_spend_regression\",\n",
    "        signature=signature\n",
    "    )\n",
    "\n",
    "    print(\"RMSE:\", rmse)\n",
    "    print(\"R2:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60fe5c8b-a7c4-48fa-8ec7-cbf7d3c35110",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 10"
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.models.signature import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "100929e9-0656-48e7-a801-b1f41a945907",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/20 06:52:42 WARNING mlflow.models.signature: Failed to infer schema for inputs. Setting schema to `Schema([ColSpec(type=AnyType())]` as default. Note that MLflow doesn't validate data types during inference for AnyType. To see the full traceback, set logging level to DEBUG.\n"
     ]
    }
   ],
   "source": [
    "# Create input example (first few rows)\n",
    "input_example = X_train.iloc[:5]\n",
    "\n",
    "# Infer model signature\n",
    "signature = infer_signature(X_train, model.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a671d330-b122-442b-bcf8-3537a5e27151",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### When logging models with MLflow and Unity Catalog, ensure all Spark-derived Decimal types are cast to floats to avoid serialization issues and enable proper schema inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6df2f1eb-ec62-4a47-b5b2-d40b9e5f14f0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 12"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert Decimal â†’ float\n",
    "for col in X.columns:\n",
    "    X[col] = X[col].astype(float)\n",
    "\n",
    "y = y.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0804891f-8f08-4cf4-b016-035541c2f675",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47ea6d90-e5de-4aa1-9235-1b084a547537",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "input_example = X_train.head(5)\n",
    "signature = infer_signature(X_train, model.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "069a9e67-77ac-4653-91b7-fc4f5410cd64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### using MLflow with Unity Catalog, models must be logged with explicit input/output signatures and examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd00b4b2-c1e1-4fca-9689-06df8c76a002",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-6425185855522582>, line 8\u001B[0m\n",
       "\u001B[1;32m      4\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n",
       "\u001B[1;32m      6\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(X_test)\n",
       "\u001B[0;32m----> 8\u001B[0m rmse \u001B[38;5;241m=\u001B[39m mean_squared_error(y_test, y_pred, squared\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
       "\u001B[1;32m      9\u001B[0m r2 \u001B[38;5;241m=\u001B[39m r2_score(y_test, y_pred)\n",
       "\u001B[1;32m     11\u001B[0m mlflow\u001B[38;5;241m.\u001B[39mlog_param(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_type\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLinearRegression\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:194\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    191\u001B[0m func_sig \u001B[38;5;241m=\u001B[39m signature(func)\n",
       "\u001B[1;32m    193\u001B[0m \u001B[38;5;66;03m# Map *args/**kwargs to the function signature\u001B[39;00m\n",
       "\u001B[0;32m--> 194\u001B[0m params \u001B[38;5;241m=\u001B[39m func_sig\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m    195\u001B[0m params\u001B[38;5;241m.\u001B[39mapply_defaults()\n",
       "\u001B[1;32m    197\u001B[0m \u001B[38;5;66;03m# ignore self/cls and positional/keyword markers\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/usr/lib/python3.12/inspect.py:3242\u001B[0m, in \u001B[0;36mSignature.bind\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m   3237\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbind\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m/\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n",
       "\u001B[1;32m   3238\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001B[39;00m\n",
       "\u001B[1;32m   3239\u001B[0m \u001B[38;5;124;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001B[39;00m\n",
       "\u001B[1;32m   3240\u001B[0m \u001B[38;5;124;03m    if the passed arguments can not be bound.\u001B[39;00m\n",
       "\u001B[1;32m   3241\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
       "\u001B[0;32m-> 3242\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bind(args, kwargs)\n",
       "\n",
       "File \u001B[0;32m/usr/lib/python3.12/inspect.py:3231\u001B[0m, in \u001B[0;36mSignature._bind\u001B[0;34m(self, args, kwargs, partial)\u001B[0m\n",
       "\u001B[1;32m   3229\u001B[0m         arguments[kwargs_param\u001B[38;5;241m.\u001B[39mname] \u001B[38;5;241m=\u001B[39m kwargs\n",
       "\u001B[1;32m   3230\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[0;32m-> 3231\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n",
       "\u001B[1;32m   3232\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgot an unexpected keyword argument \u001B[39m\u001B[38;5;132;01m{arg!r}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n",
       "\u001B[1;32m   3233\u001B[0m                 arg\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28miter\u001B[39m(kwargs))))\n",
       "\u001B[1;32m   3235\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_arguments_cls(\u001B[38;5;28mself\u001B[39m, arguments)\n",
       "\n",
       "\u001B[0;31mTypeError\u001B[0m: got an unexpected keyword argument 'squared'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "TypeError",
        "evalue": "got an unexpected keyword argument 'squared'"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>TypeError</span>: got an unexpected keyword argument 'squared'"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-6425185855522582>, line 8\u001B[0m\n\u001B[1;32m      4\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n\u001B[1;32m      6\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(X_test)\n\u001B[0;32m----> 8\u001B[0m rmse \u001B[38;5;241m=\u001B[39m mean_squared_error(y_test, y_pred, squared\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m      9\u001B[0m r2 \u001B[38;5;241m=\u001B[39m r2_score(y_test, y_pred)\n\u001B[1;32m     11\u001B[0m mlflow\u001B[38;5;241m.\u001B[39mlog_param(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_type\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLinearRegression\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:194\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    191\u001B[0m func_sig \u001B[38;5;241m=\u001B[39m signature(func)\n\u001B[1;32m    193\u001B[0m \u001B[38;5;66;03m# Map *args/**kwargs to the function signature\u001B[39;00m\n\u001B[0;32m--> 194\u001B[0m params \u001B[38;5;241m=\u001B[39m func_sig\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    195\u001B[0m params\u001B[38;5;241m.\u001B[39mapply_defaults()\n\u001B[1;32m    197\u001B[0m \u001B[38;5;66;03m# ignore self/cls and positional/keyword markers\u001B[39;00m\n",
        "File \u001B[0;32m/usr/lib/python3.12/inspect.py:3242\u001B[0m, in \u001B[0;36mSignature.bind\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3237\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbind\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m/\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   3238\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001B[39;00m\n\u001B[1;32m   3239\u001B[0m \u001B[38;5;124;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001B[39;00m\n\u001B[1;32m   3240\u001B[0m \u001B[38;5;124;03m    if the passed arguments can not be bound.\u001B[39;00m\n\u001B[1;32m   3241\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 3242\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bind(args, kwargs)\n",
        "File \u001B[0;32m/usr/lib/python3.12/inspect.py:3231\u001B[0m, in \u001B[0;36mSignature._bind\u001B[0;34m(self, args, kwargs, partial)\u001B[0m\n\u001B[1;32m   3229\u001B[0m         arguments[kwargs_param\u001B[38;5;241m.\u001B[39mname] \u001B[38;5;241m=\u001B[39m kwargs\n\u001B[1;32m   3230\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 3231\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m   3232\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgot an unexpected keyword argument \u001B[39m\u001B[38;5;132;01m{arg!r}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m   3233\u001B[0m                 arg\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28miter\u001B[39m(kwargs))))\n\u001B[1;32m   3235\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_arguments_cls(\u001B[38;5;28mself\u001B[39m, arguments)\n",
        "\u001B[0;31mTypeError\u001B[0m: got an unexpected keyword argument 'squared'"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"linear_regression_baseline\"):\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    mlflow.log_param(\"model_type\", \"LinearRegression\")\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        artifact_path=\"model\",\n",
    "        signature=signature,\n",
    "        input_example=input_example,\n",
    "        registered_model_name=\"user_spend_regression\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6159b1f9-9124-4a86-8621-77248ba81032",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "816c04ef-bd2e-4688-811a-e38c62354c79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "with mlflow.start_run(run_name=\"linear_regression_baseline\"):\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    mlflow.log_param(\"model_type\", \"LinearRegression\")\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "\n",
    "    input_example = X_train.head(5)\n",
    "    signature = infer_signature(X_train, model.predict(X_train))\n",
    "\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        artifact_path=\"model\",\n",
    "        signature=signature,\n",
    "        input_example=input_example,\n",
    "        registered_model_name=\"user_spend_regression\"\n",
    "    )\n",
    "\n",
    "    print(\"RMSE:\", rmse)\n",
    "    print(\"R2:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0faa74a1-2ba7-4ded-b55f-c67d9953266a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'user_spend_regression' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge RMSE: 417.62566638299336\nRidge R2: 0.5899802977212896\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '4' of model 'workspace.default.user_spend_regression'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "with mlflow.start_run(run_name=\"ridge_regression_baseline\"):\n",
    "\n",
    "    # Train model\n",
    "    model = Ridge(alpha=1.0)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Metrics (version-safe)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"model_type\", \"Ridge\")\n",
    "    mlflow.log_param(\"alpha\", 1.0)\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "\n",
    "    # Signature & input example (Unity Catalog compliant)\n",
    "    input_example = X_train.head(5)\n",
    "    signature = infer_signature(X_train, model.predict(X_train))\n",
    "\n",
    "    # Log & register model\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        artifact_path=\"model\",\n",
    "        signature=signature,\n",
    "        input_example=input_example,\n",
    "        registered_model_name=\"user_spend_regression\"\n",
    "    )\n",
    "\n",
    "    print(\"Ridge RMSE:\", rmse)\n",
    "    print(\"Ridge R2:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de34aeb0-c89f-430c-8f62-58ba16acf3c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2097438743550117,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Days 12-14 - AI & ML",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}